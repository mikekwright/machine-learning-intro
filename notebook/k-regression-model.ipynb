{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Lets Create a Price Adjuster\n",
    "\n",
    "So, we have an idea, to simplify the work required to find nearby rentals that are\n",
    "similar to the new rentals that I am adding and attempt to create a price calculator\n",
    "that will provide me with the best expected price from those results.   \n",
    "\n",
    "With that in mind lets start the process.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up\n",
    "\n",
    "So the first thing that we are going to do is setup our imports, so that we have all the tools\n",
    "we are going to work with loaded (don't need to load later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pd.options.display.max_rows = 4000\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Analyze the Data\n",
    "\n",
    "So to start lets look over the data that we have received, first we will\n",
    "need to load the data so that we can manipulate it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/listing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point lets do a quick check of the data for row count and even first row to sample the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Row Count: {}'.format(len(data)))\n",
    "print('-'*20)\n",
    "print(data.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the column that we are trying to determine for future entries is the price column.  Knowing that\n",
    "we need to determine which other columns we can use to create features.  \n",
    "\n",
    "Since all modeling requires that the data be represented as a numeric value, and since we are limited\n",
    "on time, we are going to focus only on columns that already have a defined numeric representation.  \n",
    "\n",
    "So we are going to ignore columns that are:  \n",
    "\n",
    "* Text\n",
    " * URL\n",
    " * Short/Long Descriptions\n",
    "* Date\n",
    "* Lat/Long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That leaves use with a number of columns still, but for our first attempt lets just use a few columns:  \n",
    "\n",
    "* bathrooms\n",
    "* bedrooms\n",
    "* beds\n",
    "* accommodates\n",
    "* region_id\n",
    "* price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bathrooms', 'bedrooms', 'beds', 'accommodates', 'region_id', 'price']\n",
    "data.dropna(axis=0, how='any', subset=columns, inplace=True)\n",
    "\n",
    "subset = data[columns]\n",
    "pprint(subset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So looking over the columns, it seems that the price column is the only one that is not already\n",
    "in a numeric type, so lets start by looking at the price value in the first 10 rows to determine\n",
    "what the data looks like.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset['price'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like it is formatted with a `$` in front, so lets convert the column value and\n",
    "translate it to a numeric type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price'] = data['price'].str.replace('$', '')\n",
    "data['price'] = data['price'].str.replace(',', '')\n",
    "data['price'] = data['price'].astype(float)\n",
    "\n",
    "subset = data[columns]\n",
    "print(subset['price'][:5])\n",
    "print(subset.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Modeling\n",
    "\n",
    "Alright so at this point we have some data to work with and have it formatted in a fashion that we\n",
    "can start creating some models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first model we are going to go with a simple regression model using **K-Nearest Neighbors**\n",
    "\n",
    "This algorithm simply takes the supplied feature vector and finds the _k_ closest examples to the\n",
    "selected vector (nearest neighbors).  In the case of regression it will take the values from each\n",
    "of the _k_ neighbors and calculate the average.  \n",
    "\n",
    "For our setup we are going to use the Euclidean Distance to determine how closely related\n",
    "two vectors are.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Formula\n",
    "\n",
    "The formula is defined below.  \n",
    "\n",
    "p - current vector\n",
    "q - comparing vector\n",
    "\n",
    "\\begin{equation*}\n",
    "distance = \\sqrt{(p_1-q_1)^2 + (p_2-q_2)^2 + \\cdots + (p_n-q_n)^2}\n",
    "\\end{equation*}\n",
    "\n",
    "or shorter form\n",
    "\n",
    "\\begin{equation*}\n",
    "distance = \\sqrt{\\sum_{i=0}^{n}(p_i-q_i)^2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now lets go through an example of how we can use this to calculate the distance.  \n",
    "\n",
    "In this example we are going to use only two of the features (bathrooms, bedrooms) and compare\n",
    "the distance for the first two rows.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bathrooms', 'bedrooms']\n",
    "p = subset[features].iloc[0]\n",
    "q = subset[features].iloc[1]\n",
    "print('p')\n",
    "print('-'*20)\n",
    "print(p)\n",
    "print('q')\n",
    "print('-'*20)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = np.sqrt(np.sum(np.square(p-q)))\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets check our math to make sure this is correct.  \n",
    "\n",
    "\\begin{equation*}\n",
    "2.0 = \\sqrt{(1-1)^2 + (1-3)^2}\n",
    "\\end{equation*}\n",
    "\n",
    "Looks good to me, this means that the distance between the first two entries is 2.0.  \n",
    "\n",
    "Lets go ahead and calculate the distance between our selected entry and the rest of the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = subset.iloc[0]\n",
    "subset = subset[1:]\n",
    "subset['distance'] = subset[features].apply(lambda q: np.sqrt(np.sum(np.square(p[features]-q))), axis=1)\n",
    "print(subset['distance'].value_counts().head(5))\n",
    "print(subset.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like we actually have 1264 neighbors... that are the closest (as close as possible)\n",
    "and if we wanted to select _k_ of them, we would need to make sure that we are `unbiased` in our\n",
    "selection, so lets sort the distance values (and randomize them when they are close).  \n",
    "\n",
    "After doing that we can select the top _k_ rows (in this case lets go with the 5 closest neighbors). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_order = np.random.permutation(len(subset))\n",
    "subset = subset.loc[random_order]\n",
    "#subset.sort_values(['distance'], inplace=True)\n",
    "neighbors = subset[:5]\n",
    "print(subset.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our neighbors we can compare the mean price of the neighbors\n",
    "and use that to determine how close we are to the actual price of our selected\n",
    "entry.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_price = neighbors['price'].mean()\n",
    "p_price = p['price']\n",
    "print(f'estimated price: {mean_price}')\n",
    "print(f'actual price: {p_price}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have an estimated price and an actual price that we generated using the 5 nearest neighbors.  \n",
    "Now we need to take these values and calculate the error that we introduced.  \n",
    "\n",
    "This can be done by using an algorithm named the _Mean Absolute Error_ or (MAE).  The MAE algorithm\n",
    "is defined below.  \n",
    "\n",
    "\\begin{equation*}\n",
    "error = \\dfrac{|g_0 - a_0| + |g_1 - a_1| + \\cdots + |g_n - a_n|}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "or the simplier form\n",
    "\n",
    "\\begin{equation*}\n",
    "error = \\dfrac{\\sum_{i=0}^{n}{|(g_i - a_i)|}}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "In our case n = 1 so we can simplify it to\n",
    "\n",
    "\\begin{equation*}\n",
    "error = |m - p|\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.abs(mean_price - p_price)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is one thing that we will want to do when calculating an error, we actually want values\n",
    "that are farther from the true value to be penalized more.  This can be accomplished using the\n",
    "MSE or _Mean Squared Error_.  \n",
    "\n",
    "\\begin{equation*}\n",
    "error = \\dfrac{\\sum_{i=0}^{n}{(g_i - a_i)^2}}{n}\n",
    "\\end{equation*}\n",
    "\n",
    "Of course this means that the value losses its representation and we can no longer consider it to \n",
    "represent a dollar, although that can be fixed just by taking the sqrt of the MSE. \n",
    "\n",
    "\\begin{equation*}\n",
    "error = \\sqrt{\\dfrac{\\sum_{i=0}^{n}{(g_i - a_i)^2}}{n}}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Sklearn implementation\n",
    "\n",
    "At this point we have gone over our own version of the *K Nearest Neighbor* using the\n",
    "Euclidean distance algorithm and determined the error.  These algorithms have actually\n",
    "all been created before (and optimized).  So instead of re-inventing the wheel, lets \n",
    "see how we can quickly create a model using the sklearn framework.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "subset = data[columns]\n",
    "p = subset.iloc[0]\n",
    "subset = subset[1:]\n",
    "\n",
    "model = KNeighborsRegressor(algorithm='brute', n_neighbors=5)\n",
    "# fit our model (calculate the distances), specify the value to use for regression\n",
    "model.fit(subset[features], subset['price'])\n",
    "# test our model out \n",
    "#  Note: we are reshaping the input so that as per sklearn's requirement for single samples\n",
    "predictions = model.predict(p[features].values.reshape(1, -1))\n",
    "error = mean_squared_error([p['price']], predictions)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now this shows the MSE for a single sample, the top one.  What we really want to do is to \n",
    "take a subset of our data and split it into two groups, training data and test data.  \n",
    "\n",
    "The rule of thumb for seperating this data is to use ~70% as the training data, and the\n",
    "other ~20% as the testing data.  \n",
    "\n",
    "So here lets create our train and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from math import floor\n",
    "\n",
    "subset = data[columns]\n",
    "subset = shuffle(subset)\n",
    "\n",
    "data_size = len(subset)\n",
    "split_index = floor(data_size*.7)\n",
    "training_set = data[:split_index]\n",
    "test_set = data[split_index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets re-run our above code using the training_set and test_set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(algorithm='brute', n_neighbors=5)\n",
    "# fit our model (calculate the distances), specify the value to use for regression\n",
    "model.fit(training_set[features], training_set['price'])\n",
    "# test our model out \n",
    "#  Note: we are reshaping the input so that as per sklearn's requirement for single samples\n",
    "predictions = model.predict(test_set[features])\n",
    "error = mean_squared_error(test_set['price'], predictions)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have our error on our testing and training set, lets create a function that we can use\n",
    "to quickly run this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(features, k):\n",
    "    model = KNeighborsRegressor(algorithm='brute', n_neighbors=k)\n",
    "    model.fit(training_set[features], training_set['price'])\n",
    "    predictions = model.predict(test_set[features])\n",
    "    error = mean_squared_error(test_set['price'], predictions)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have a way to adjust our features, as well as our single hyper parameter.  Lets\n",
    "try it out by using the same features that we have been using (bedrooms, bathrooms) but by adjusting\n",
    "the _k_ value (from 1 to 10).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_values = []\n",
    "k_range = list(range(1, 11))\n",
    "for k in k_range:\n",
    "    error_values.append(test_model(features, k))\n",
    "pprint(error_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this might be a nice list... it isn't the best for us to quickly see how well our model is working\n",
    "with the different hyper parameter value, so lets try to visual the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(k_range, error_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so right now it looks like the data is still getting better when we get to the point of\n",
    "using `k=10`.  \n",
    "\n",
    "Lets try it with more k values, from 1 to 40 this time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_values = []\n",
    "k_range = list(range(1, 41))\n",
    "for k in k_range:\n",
    "    error_values.append(test_model(features, k))\n",
    "\n",
    "plt.scatter(k_range, error_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting, so from what is shown above, it seems that a k value of 28 seems to be our best bet.  \n",
    "\n",
    "Lets go ahead and create another function, one that does a k value search but allows you to use different\n",
    "features and just returns the best k value and error it sees.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_search(features, max_k=40):\n",
    "    min_result = None\n",
    "    for k in range(1, max_k+1):\n",
    "        error = test_model(features, k)\n",
    "        if min_result is None or error < min_result[1]:\n",
    "            min_result = k, error, np.sqrt(error)\n",
    "    return min_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets run some experiments with a few different feature sets.  \n",
    "\n",
    "* `['bathrooms', 'bedrooms']`\n",
    "* `['accomodates']`\n",
    "* `['accomodates', 'region_id']`\n",
    "* `['bedrooms', 'beds', 'region_id']`\n",
    "* `['accomodates', 'beds']`\n",
    "* `['accomodates', 'bathrooms', 'bedrooms']`\n",
    "* `['accomodates', 'beds', 'bathrooms', 'bedrooms']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [\n",
    "    ['bathrooms', 'bedrooms'],\n",
    "    ['accommodates'],\n",
    "    ['accommodates', 'region_id'],\n",
    "    ['bedrooms', 'beds', 'region_id'],\n",
    "    ['accommodates', 'beds'],\n",
    "    ['accommodates', 'bathrooms', 'bedrooms'],\n",
    "    ['accommodates', 'beds', 'bathrooms', 'bedrooms'],\n",
    "]\n",
    "\n",
    "error_values = []\n",
    "for fs in feature_sets:\n",
    "    error_values.append(k_search(fs))\n",
    "    \n",
    "pprint(error_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "So it appears that our best model is one that is built using 'accommodates' as the selected\n",
    "feature, with a _k_ value of 4.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
