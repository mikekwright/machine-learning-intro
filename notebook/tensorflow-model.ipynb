{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets Create a Price Adjuster (Deep Network)\n",
    "\n",
    "Alright, so now let us see if we can come up with a deep network solution and see how it\n",
    "compares to the K Nearest Neighbors we just implemented.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by loading and adjusting our data like we did in our last tutorial.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('../data/listing.csv')\n",
    "\n",
    "columns = ['bathrooms', 'bedrooms', 'beds', 'accommodates', 'price']\n",
    "data.dropna(axis=0, how='any', subset=columns, inplace=True)\n",
    "\n",
    "data['price'] = data['price'].str.replace('$', '')\n",
    "data['price'] = data['price'].str.replace(',', '')\n",
    "data['price'] = data['price'].astype(float)\n",
    "\n",
    "data = data[columns]\n",
    "\n",
    "train_set, test_set = train_test_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first thing we are going to do is to define our inputs into the network.  For our\n",
    "current setup we are going to use continuous values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lets start by defining our initial network....\n",
    "\n",
    "input_count = len(columns)-1\n",
    "output_count = 1\n",
    "hidden_size = 100  # This is a hyper parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now we need the input and output placeholders in tensorflow\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, input_count])\n",
    "Y = tf.placeholder(tf.float32, [None, output_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## There are a couple of other variables that we need\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## At this point we need to create our weights and biases for the layer connections\n",
    "\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([input_count, hidden_size])),\n",
    "    'output': tf.Variable(tf.random_normal([hidden_size, output_count])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([hidden_size])),\n",
    "    'output': tf.Variable(tf.random_normal([output_count])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## So now we can create out network\n",
    "\n",
    "hidden_layer = tf.add(tf.matmul(X, weights['hidden']), biases['hidden'])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "output_layer = tf.matmul(hidden_layer, weights['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lets define the cost function that our network will use to use with accuracy\n",
    "\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=Y))\n",
    "loss = tf.reduce_sum(tf.square(Y - output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## At this point we can teach it how to 'learn' (basically which optimizer it should use)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## So lets first initialize all the variables\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    label_set = train_set['price'].values.reshape(-1, output_count)\n",
    "    #batch_set = train_set.drop('price', 1).reshape(-1, input_num_units)\n",
    "    batch_set = train_set.drop('price', 1)\n",
    "    sess.run([optimizer, loss], feed_dict = {X: batch_set, Y: label_set})\n",
    "\n",
    "    pred_temp = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(pred_temp, 'float'))\n",
    "    \n",
    "    print('Validation Accuracy: {}'.format(accuracy.eval({X: batch_set, Y: label_set})))    \n",
    "    #print \"Validation Accuracy:\", accuracy.eval({x: val_x.reshape(-1, input_count), y: dense_to_one_hot(val_y)})\n",
    "\n",
    "    test_label_set = test_set['price'].values.reshape(-1, output_count)\n",
    "    test_batch_set = test_set.drop('price', 1)\n",
    "    \n",
    "    predict = tf.argmax(output_layer, 1)\n",
    "    pred = predict.eval({X: test_batch_set})\n",
    "    \n",
    "    print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
